{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import defaultdict\n",
    "import operator\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim import models, corpora, similarities\n",
    "from sklearn import svm\n",
    "from sklearn import linear_model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_csv(\"tiantian_news_cutforsearch.csv\")\n",
    "data = pd.read_csv(\"raw_data/tiantian_news_cut.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data.loc[data[\"cutwords\"].isnull()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categories():\n",
    "    input_file = \"conf/categories.txt\"\n",
    "    with open(input_file, \"rb\") as f:\n",
    "        result = f.readlines()\n",
    "        result = [x.strip('\\n').decode('utf8') for x in result]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = get_categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n422067\n"
     ]
    }
   ],
   "source": [
    "sample_num = 5000\n",
    "train = pd.DataFrame()\n",
    "test = pd.DataFrame()\n",
    "\n",
    "for cat in categories:\n",
    "    data_onecat = data[data[\"category\"] == cat.encode(\"utf8\")]\n",
    "    train_onecat = data_onecat.sample(n=sample_num)\n",
    "    test_onecat = data_onecat.drop(train_onecat.index)\n",
    "    train = pd.concat([train, train_onecat])\n",
    "    test = pd.concat([test, test_onecat])\n",
    "# test = test.sample(n=10000)\n",
    "print len(train)\n",
    "print len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_documents = train[\"cutwords\"].tolist()\n",
    "train_texts = [[word for word in document.split()] for document in train_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_documents = test[\"cutwords\"].tolist()\n",
    "test_texts = [[word for word in document.split()] for document in test_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vec = CountVectorizer()\n",
    "train_documents_counts = count_vec.fit_transform(train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 722913)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_documents_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "train_x_tfidf = tfidf_transformer.fit_transform(train_documents_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 722913)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_documents_counts = count_vec.transform(test_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x_tfidf = tfidf_transformer.transform(test_documents_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_data = pd.concat([train, test])\n",
    "clean_data[\"category\"] = clean_data[\"category\"].astype(\"category\")\n",
    "clean_data[\"category_encoded\"] = clean_data[\"category\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = clean_data[:sample_num * len(categories)]\n",
    "test = clean_data[sample_num * len(categories):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n422067\n(100000, 722913)\n"
     ]
    }
   ],
   "source": [
    "print len(train)\n",
    "print len(test)\n",
    "print train_x_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train[\"category_encoded\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test[\"category_encoded\"].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_svm_1 = svm.SVC(C=100)\n",
    "# clf_svm_1.fit(train_x_tfidf, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_svm_2 = svm.SVC(C=10)\n",
    "# clf_svm_2.fit(train_x_tfidf, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf_lr_1 = linear_model.LogisticRegression(C=1, solver=\"sag\", multi_class=\"multinomial\", verbose=100, n_jobs=-1)\n",
    "# clf_lr_1.fit(train_x_tfidf, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 1.85381794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.615400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2, loss = 1.05445769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.745600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.71809940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.742900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.60121207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.744500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5, loss = 0.55214013\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.753000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6, loss = 0.51895668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.753300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7, loss = 0.48503793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.746000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8, loss = 0.46536983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.751700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9, loss = 0.45474121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score: 0.742400\nValidation score did not improve more than tol=0.000100 for two consecutive epochs. Stopping.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n       beta_2=0.999, early_stopping=True, epsilon=1e-08,\n       hidden_layer_sizes=(100, 2), learning_rate='constant',\n       learning_rate_init=0.01, max_iter=200, momentum=0.9,\n       nesterovs_momentum=True, power_t=0.5, random_state=None,\n       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n       verbose=True, warm_start=False)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_lr_1 = MLPClassifier(hidden_layer_sizes=(100, 2), learning_rate_init=0.01, verbose=True, early_stopping=True)\n",
    "clf_lr_1.fit(train_x_tfidf, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# joblib.dump(clf_svm_1, \"svm_1_allfeas.pkl\")\n",
    "# joblib.dump(clf_svm_2, \"svm_2_allfeas.pkl\")\n",
    "# joblib.dump(clf_lr_1, \"lr_1_allfeas.pkl\")\n",
    "# joblib.dump(clf_lr_2, \"lr_2_allfeas.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_num_1 = 0\n",
    "correct_num_2 = 0\n",
    "with open(\"logs/run_2.log\", \"ab\") as f:\n",
    "    f.write(\"lr\\n\")\n",
    "for i in range(test_x_tfidf.shape[0]):\n",
    "    predict_1 = clf_lr_1.predict(test_x_tfidf[i])\n",
    "    # predict_2 = clf_lr_2.predict(test_x_tfidf[i])\n",
    "    if predict_1[0] == test_y[i]:\n",
    "        correct_num_1 += 1\n",
    "    # if predict_2[0] == test_y[i]:\n",
    "    #     correct_num_2 += 1\n",
    "    if i % 100 == 0:\n",
    "        with open(\"logs/run_2.log\", \"ab\") as f:\n",
    "            f.write(\"{}, {}, {}\\n\".format(i, correct_num_1, correct_num_2))\n",
    "print float(correct_num_1) * 100 / test_x_tfidf.shape[0]\n",
    "print float(correct_num_2) * 100 / test_x_tfidf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.5868926024\n0.0\n"
     ]
    }
   ],
   "source": [
    "print float(correct_num_1) * 100 / test_x_tfidf.shape[0]\n",
    "print float(correct_num_2) * 100 / test_x_tfidf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct_num_1 = 0\n",
    "# correct_num_2 = 0\n",
    "# with open(\"logs/run_2.log\", \"ab\") as f:\n",
    "#     f.write(\"svm\\n\")\n",
    "# for i in range(test_x_tfidf.shape[0]):\n",
    "#     predict_1 = clf_svm_1.predict(test_x_tfidf[i])\n",
    "#     predict_2 = clf_svm_2.predict(test_x_tfidf[i])\n",
    "#     if predict_1[0] == test_y[i]:\n",
    "#         correct_num_1 += 1\n",
    "#     if predict_2[0] == test_y[i]:\n",
    "#         correct_num_2 += 1\n",
    "#     if i % 100 == 0:\n",
    "#         with open(\"logs/run_2.log\", \"ab\") as f:\n",
    "#             f.write(\"{}, {}, {}\\n\".format(i, correct_num_1, correct_num_2))\n",
    "# print float(correct_num_1) * 100 / test_x_tfidf.shape[0]\n",
    "# print float(correct_num_2) * 100 / test_x_tfidf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}